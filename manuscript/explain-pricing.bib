
@article{kuoDeepTriangleDeep2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1804.09253},
  primaryClass = {cs, q-fin, stat},
  title = {{{DeepTriangle}}: {{A Deep Learning Approach}} to {{Loss Reserving}}},
  shorttitle = {{{DeepTriangle}}},
  abstract = {We propose a novel approach for loss reserving based on deep neural networks. The approach allows for joint modeling of paid losses and claims outstanding, and incorporation of heterogeneous inputs. We validate the models on loss reserving data across lines of business, and show that they improve on the predictive accuracy of existing stochastic methods. The models require minimal feature engineering and expert input, and can be automated to produce forecasts more frequently than manual workflows.},
  journal = {arXiv:1804.09253 [cs, q-fin, stat]},
  author = {Kuo, Kevin},
  month = apr,
  year = {2018},
  keywords = {Computer Science - Machine Learning,Quantitative Finance - Risk Management,Statistics - Applications,loss-reserving}
}

@article{wuthrichMachineLearning2018,
  title = {Machine Learning in Individual Claims Reserving},
  volume = {2018},
  number = {6},
  journal = {Scandinavian Actuarial Journal},
  author = {W{\"u}thrich, Mario V.},
  year = {2018},
  pages = {465--480}
}

@article{gabrielliNeuralNetwork2019a,
  title = {Neural Network Embedding of the Over-Dispersed {{Poisson}} Reserving Model},
  journal = {Scandinavian Actuarial Journal},
  author = {Gabrielli, Andrea and Richman, Ronald and W{\"u}thrich, Mario V.},
  year = {2019},
  pages = {1--29}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  volume = {521},
  number = {7553},
  journal = {Nature},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  pages = {436}
}

@techreport{gabrielliNeuralNetwork2019,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {A {{Neural Network Boosted Double Over}}-{{Dispersed Poisson Claims Reserving Model}}},
  abstract = {We present an actuarial loss reserving technique that takes into account both claim counts and claim amounts. Separate (over-dispersed) Poisson models for the claim counts and the claim amounts are combined by a joint embedding into a neural network architecture. As starting point of the neural network calibration we use exactly these two separate (over-dispersed) Poisson models. Such a nested model can be interpreted as a boosting machine. It allows us for joint modeling and mutual learning of claim counts and claim amounts beyond the two individual (over-dispersed) Poisson models. Moreover, this choice of neural network initialization guarantees stability and accelerates representation learning.},
  language = {en},
  number = {ID 3365517},
  institution = {{Social Science Research Network}},
  author = {Gabrielli, Andrea},
  month = apr,
  year = {2019},
  keywords = {boosting,chain-ladder reserves,claim amounts,claim counts,claims reserving in insurance,cross-classified over-dispersed Poisson model,double chain-ladder,embedding,learning across portfolios,neural network}
}

@article{doshi-velezRigorousScience2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1702.08608},
  primaryClass = {cs, stat},
  title = {Towards {{A Rigorous Science}} of {{Interpretable Machine Learning}}},
  abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
  journal = {arXiv:1702.08608 [cs, stat]},
  author = {{Doshi-Velez}, Finale and Kim, Been},
  month = feb,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
}


